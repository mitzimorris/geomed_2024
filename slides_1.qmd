---
title: Spatial Modeling in Stan
author: Mitzi Morris
institute: Stan Development Team
date: Sept 9, 2024
format:
  beamer:
    syntax-definitions:
      - "theming/stan.xml"
    highlight-style: tango
    aspectratio: 169
    pdf-engine: pdflatex
    theme: metropolis
    include-in-header: preamble.tex
    navigation: horizontal
    dev: png 
    linkcolor: "DarkBlue"
    urlcolor: "DarkBlue"
---

# Overview
\vspace*{-20pt}

### Workshop Goal

Learn how to use existing models and develop new ones.

### Outline: Part One

* About Stan

* Stan Workflow

* ICAR Model for Spatial Smoothing



# What is Stan?

\tightlist
* A Probabilistic Programming Language
  + A Stan program defines a probability model

\vspace*{4pt}
* A Collection of Inference Algorithms
  + Exact Bayesian inference using MCMC (NUTS-HMC)
  + Aproximate Bayesian inference using ADVI, Pathfinder
  + Point estimates using optimization, Laplace approximation

\vspace*{4pt}
* Interfaces and Analysis Tools
  + R: [CmdStanR](https://mc-stan.org/cmdstanr/), [Posterior](https://mc-stan.org/posterior/), [Bayesplot](https://mc-stan.org/bayesplot/), [LOO](https://mc-stan.org/loo/) (Also:  RStan, RStanARM, BRMS)
  + Python: [CmdStanPy](https://mc-stan.org/cmdstanpy/), [ArviZ](https://python.arviz.org/en/stable/)
  + Julia: [Stan.jl](https://stanjulia.github.io/Stan.jl/v10.8/), [ArviZ.jl](https://julia.arviz.org/ArviZ/stable/)
  + Command shell: [CmdStan](https://mc-stan.org/docs/cmdstan-guide/)


# Why Stan?

\tightlist

* **Goal**: Develop multi-level models for real-world applications

\vspace*{8pt}
* *Problem*:  Need descriptive power, clarity of BUGS
* *Solution*: Compile a domain-specific language

 . . .

\vspace*{8pt}
* *Problem*:  Pure directed graphical language inflexible
* *Solution*: Imperative probabilistic programming language

 . . .

\vspace*{8pt}
* *Problem*:  Heterogeneous user base
* *Solution*: Many interfaces (R, Python, Julia, Mathematica, MATLAB), domain-specific examples, case studies, and field guides

 . . .

\vspace*{8pt}
* *Problem*:  Restrictive licensing limits use
* *Solution*: Code and doc open source (BSD, CC-BY)

# Why Stan?

\tightlist
* **Goal**: Robust, fully Bayesian inference.

\vspace*{8pt}
* *Problem*: Gibbs and Metropolis too slow (diffusive)
* *Solution*: Hamiltonian Monte Carlo (flow of Hamiltonian dynamics)

 . . .

\vspace*{8pt}
* *Problem*:  Need to tune parameters for HMC
* *Solution*: Tune step size and estimate mass matrix during warmup;\
determine number of steps on-the-fly (NUTS)

 . . .

\vspace*{8pt}
* *Problem*:  Need gradients of log posterior for HMC
* *Solution*: Reverse-mode algorithmic differentiation

 . . .

\vspace*{8pt}
* *Problem*:  Need unconstrained parameters for HMC
* *Solution*: Variable transforms w. Jacobian determinants

# NUTS-HMC vs.\ Gibbs and Metropolis

\includegraphics[width=0.9\textwidth]{img/nuts-vs.pdf}

* Plot shows 2 dimensions of highly correlated 250-dim normal
* **1,000,000 draws** from Metropolis and Gibbs (thin to 1000)
* **1000 draws** from NUTS (no thinning); 1000 independent draws
\fontsize{9pt}{9.4}\selectfont
* [*The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo*](http://jmlr.org/papers/v15/hoffman14a.html), fig. 7
\normalsize

# MCMC Sampling Efficiency
\tightlist
* MCMC samples have autocorrelation

* $N_{\mbox{\footnotesize eff}}$ is the number of independent samples with the same estimation power\
as the $N$ autocorrelated samples.

* When comparing algorithms, compare $N_{\mbox{\footnotesize eff}}$ **per second**

\vspace{0.05in}
* Gibbs and Metropolis have
  + High iterations per second but low effective samples per iteration
  + Both are weak when there is high correlation among the parameters in the posterior

\vspace{0.05in}
* Hamiltonian Monte Carlo \& NUTS
  + Fewer iterations per second than Gibbs or Metropolis
  + But *much* higher $N_{\mbox{\footnotesize eff}}$ per second
  + More robust to highly correlated or differently scaled parameters.

# Other Supported Inference Algorithms

Faster, more scalable methods
\vspace{0.1in}

\tightlist
* Variational Inference\
Generate samples from a variational approximation to the posterior distribution
   + [ADVI](https://www.jmlr.org/papers/volume18/16-107/16-107.pdf) - use stochastic gradient ascent
   + Pathfinder - follow quasi-Newton optimization path


\vspace{0.05in}
* Optimization: find posterior mode
   + MLE - maximum likelihood estimate (of the data given the parameters)
   + MAP - maximum a posteriori estimate (of the value of the posterior density\
on the unconstrained scale)
   + Laplace approximation - obtain samples from posterior mode


# Stan Toolset

* Programming language interfaces:  CmdStanR, CmdStanPy, Stan.jl, (MatLabStan)
  + Core methods for model compilation, doing inference, accessing results

\vspace{0.05in}
* Tools for visualization and validation:  Bayesplot, LOO, ArviZ, Arviz.jl
  + Evaluate the goodness of fit; make plots to communicate findings
  
\vspace{0.05in}
* Higher Level Interface for R: BRMS - Bayesian Regression Models in Stan
  + Model specification via extended R formula, data supplied as R dataframe
  + BRMS translates formula to Stan, creates list of inputs from dataframe,\
runs NUTS-HMC sampler, checks inferences.


\vspace{0.05in}
* BridgeStan - algorithm development and exploration
  + Evaluate the log posterior density at a point
  + Constrain/unconstrain model parameters


# The Stan Language

\tightlist
* A Stan program
  + Declares data and (constrained) parameter variables
  + Defines log posterior (or penalized likelihood)
  + Computes quantities of interest

* Syntax
  + Influenced by BUGS (plus Java/C++ punctuation)
  + Explicit variable types (like Java/C++, not like Python, R)
  + Named program blocks - distinguish between data and parameters (not like BUGS)
  + Control flow:  `if` statements - dynamic branch points (more powerful than BUGS)

* Mathematical operations
  + Stan language includes a very large set of probability distributions\
and mathematical functions from Stan's math library
  + Efficient, vectorized (almost always)

# Stan Example: Laplace's Model of Birth Rate by Sex

\vspace{-0.1in}
Laplace's data on live births in Paris from 1745--1770:

\begin{center}\small
\begin{tabular}{c|c}
{\slshape sex} & {\slshape live births}
\\ \hline
female & 241\,945
\\
male & 251\,527
\end{tabular}
\end{center}

\vspace*{0.1in}

* *Question 1* (Estimation): What is the birth rate of boys vs. girls?

* *Question 2* (Event Probability): Is a boy more likely to be born than a girl?


\vspace*{0.15in}
Laplace computed this analytically.  Let's use Stan's NUTS-HMC sampler instead.


# Laplace's Model in Stan

\fontsize{9pt}{9.4}\selectfont
```stan
transformed data {
  int male = 251527;
  int female = 241945;
}
parameters {
  real<lower=0, upper=1> theta;
}
model {
  male ~ binomial(male + female, theta);
}
generated quantities {
  int<lower=0, upper=1> theta_gt_half = (theta > 0.5);
}
```
\normalsize


# Laplace's Answer
\vspace{-0.1in}

\fontsize{9pt}{9.4}\selectfont
```
births_model = cmdstan_model("laplace.stan")   # compile model
births_fit = births_model$sample()             # run inference algorithm
as.data.frame(births_fit$summary())            # manage results

      variable       mean     median       sd         q5         q95

         theta       0.51       0.51 0.000725      0.509       0.511
 theta_gt_half       1.00       1.00 0.000000      1.000       1.000
```
\normalsize

\vspace{0.1in}
* *Question 1* (Estimation): What is the birth rate of boys vs. girls?\
$\theta$ is 90\% certain to lie in $(0.509, 0.511)$

* *Question 2* (Event Probability): Is a boy more likely to be born than a girl?\
Laplace "morally certain" boys more prevalent


# Stan Program File

A Stan program consists of one or more named program blocks, strictly ordered

\fontsize{9pt}{9.4}\selectfont
```stan
functions {
  // declare, define functions
} data {
  // declare input data
} transformed data {
   // transform inputs, define program data
} parameters {
   // declare (continuous) parameters
} transformed parameters {
   // define derived parameters
} model {
   // compute the log joint distribution
} generated quantities {
   // define quantities of interest
}
```
\normalsize

# Stan Program Blocks - Execution During Sampling

* `data`, `transformed data` blocks - executed once on startup

* `parameters` - 
   + on startup: initialize parameters
   + at every step of inference algorithm: validate constraints

* `transformed parameters`, `model` blocks - executed every *step* of the sampler

* `generated quantities` - executed every *iteration* of the sampler

\vspace*{4pt}
* After every sampler interation, program outputs current values of all variables\
in parameters, transformed parameters, and generated quantities blocks.

# The Stan Language

\tightlist
* Variables have strong, static types
  + Strong:  only values of that type will be assignable to the variable,\
(type promotion allowed, e.g., `int` to `real`, `complex`)
  + Static: variable type is constant throughout program
  + Types: [vector, row_vector, matrix](https://mc-stan.org/docs/reference-manual/types.html#vector-and-matrix-data-types), [complex](https://mc-stan.org/docs/reference-manual/types.html#complex-numerical-data-type),
[array](https://mc-stan.org/docs/reference-manual/types.html#array-data-types.section), and [tuple](https://mc-stan.org/docs/reference-manual/types.html#tuple-data-type)
  + Variables can be declared with constraints on [upper and/or lower bounds](https://mc-stan.org/docs/reference-manual/types.html#variable-types-vs.-constraints-and-sizes)
  
* Motivation
  + Static types make programs easier to comprehend, debug, and maintain
  + Programming errors can be detected at compile-time
  + Constrained types catch runtime errors

\vspace*{4pt}
\fontsize{9pt}{9.4}\selectfont
```stan
  int<lower=0> N, N_time;                     // constraint applies to both N, N_time
  vector[3]<lower=0> sigma;
  array[3] matrix[M, N] some_xs;
  array[N] int<lower=0, upper=N_time> time;  // use arrays for structured int data 
```
\normalsize

# The Stan Language

The `model` block

\tightlist
* defines the joint log probability density function given parameters
* this function is the sum of all distribution and log probability increment statements
in the model block

\vspace*{8pt}
[Distribution statements](https://mc-stan.org/docs/reference-manual/statements.html#distribution-statements.section)
\fontsize{9pt}{9.4}\selectfont
```stan
y ~ normal(mu, sigma);
mu ~ normal(0, 10);
sigma ~ normal(0, 1);
```
\normalsize

\vspace*{8pt}
[Log probability increment statements](https://mc-stan.org/docs/reference-manual/statements.html#log-probability-increment-vs.-distribution-statement)
\fontsize{9pt}{9.4}\selectfont
```stan
target += normal_lpdf(y | mu, sigma);
target += normal_lpdf(mu | 0, 10);
target += normal_lpdf(sigma | 0, 1);
```
\normalsize



# Processing Steps

* Compile model
  + Stan compiler translates Stan file to C++ file
  + C++ file is compiled to executable program, via GNU Make
  + *prerequisites: a C++17 compiler, GNU-Make*\
*both CmdStanPy and CmdStanR have utilities to install these*

* Run inference algorithm
  + Interfaces run the compiled executable (as a subprocess) and\
manage the per-chain outputs (modified CSV format files)

* Get results via interface methods
  + Parse CSV outputs into in-memory object
  + Access individual parameters and quantities of interest
  + Run summary and diagnostic reports


# Install Stan


*  If you don't already have Stan running on your machine, 10 minutes to get it working now.
   + *If you already have Stan running on your machine, please help your neighbor.*

\vspace*{8pt}
* See handout:  `h1_install_stan.html`


# Notebook: Spatial Data for Python and R

Dataset taken from
[Bayesian Hierarchical Spatial Models: Implementing the Besag York Mollié Model in Stan](https://www.sciencedirect.com/science/article/pii/S1877584518301175).

\tightlist
* Aggregated counts of car vs. child traffic accidents, localized to US Census tract.  Per-tract data includes:
  + raw counts of accidents, population
  + measures of foot traffic, car traffic
  + socio-economic indicators:  median income, neighborhood transiency

* Handouts
  * `h2_spatial_data.html`
  * R version `h2_spatial_data.Rmd`
  * Python version: `h2_spatial_data.ipynb`



# Stan Model Building Workflow

\vspace*{-0.2in}

When writing a Stan model, as when writing any other computer program,\
*the fastest way to success is to go slowly.*

\vspace*{8pt}

* Incremental development
   + Write a (simple) model
   + Fit the model to data (either simulated or observed)
   + Check the fit 

* Then modify *(stepwise)* and repeat

* Compare successive models


# Base Model:  Poisson Regression

##### Data

- `N` - the number of census tracts
- `y` - the array of observed outcomes - accidents per tract
- `E` - the population per tract ("exposure")
- `K` - the number of predictors
- `xs` - the N x K data matrix of predictors

##### Regression Parameters

- `beta0` - global intercept
- `betas` - a K-length vector of regression co-efficients



# Base Model:  Poisson Regression

##### Distribution statement (likelihood)

\fontsize{9pt}{9.4}\selectfont
```stan
  y ~ poisson_log(log(E) + beta0 + X * betas);
```
\normalsize

- **`poisson_log`** distribution uses the log rate as a parameter
   + don't need to exponentiate, better numerical stability

- **`poisson_log_rng`** pseudo-random number generator function (PRNG function)
  +  [PRNG functions](https://mc-stan.org/docs/stan-users-guide/user-functions.html#functions-acting-as-random-number-generators) used to replicate, simulate data.

  + Poisson variate is an **integer**,  largest integer value is $2^{30}$,
argument to `poisson_log_rng` must be less than $30 \log 2$, $\approx 28$



# Base Stan Program

\fontsize{9pt}{9.4}\selectfont
```stan
data {
  int<lower=0> N;
  array[N] int<lower=0> y; // count outcomes
  vector<lower=0>[N] E; // exposure
  int<lower=1> K; // num covariates
  matrix[N, K] xs; // design matrix
}
transformed data {
  vector[N] log_E = log(E);
}
parameters {
  real beta0; // intercept
  vector[K] betas; // covariates
}
model {
  y ~ poisson_log(log_E + beta0 + xs * betas);  // likelihood
  beta0 ~ std_normal(); betas ~ std_normal();   // priors
}
```
\normalsize

# Posterior Predictive Checks

* The posterior predictive distribution is the distribution over new observations given previous observations.

* In the absence of new observations, we can simulate new observations, `y_rep` in the `generated quantities` block.

$y^{\textrm{rep}}$ of the original data set $y$ given model parameters
$\theta$ is defined by
$$
p(y^{\textrm{rep}} \mid y)
= \int p(y^{\textrm{rep}} \mid \theta)
       \cdot p(\theta \mid y) \, \textrm{d}\theta.
$$


# Base Stan Program - Generated Quantities Block

\fontsize{9pt}{9.4}\selectfont
```stan
generated quantities {
  array[N] int y_rep;
  vector[N] log_lik;
  { // local block variables not recorded
    vector[N] eta = log_E + beta0 + xs * betas;
    if (max(eta) > 26) { // avoid overflow in poisson_log_rng
      print("max eta too big: ", max(eta));
      for (n in 1:N) {
        y_rep[n] = -1;  log_lik[n] = -1;
      }
    } else {
      for (n in 1:N) {
        y_rep[n] = poisson_log_rng(eta[n]);
        log_lik[n] = poisson_log_lpmf(y[n] | eta[n]);
      }
    }
  }
}
```
\normalsize

# Notebook: Stan Model Building Workflow

* Start with base model
* Best practice one:  mean-center, scale predictor data
* Refine model
* Check fits, compare models

* Handouts
  + `h3_stan_workflow.html`
  + R version `h3_stan_workflow.Rmd`
  + Python version: `h3_stan_workflow.ipynb`


# Notebook Two: ICAR model

This notebook shows how to code the ICAR model for spatial smoothing (Besag 1973) in Stan.

# References


* \href{https://mc-stan.org/docs/stan-users-guide/index.html}{Stan User's Guide}
* \href{https://bob-carpenter.github.io/stan-getting-started/stan-getting-started.html}{Getting Started with Bayesian Statistics}
* \href {https://www.usgs.gov/faqs/what-geographic-information-system-gis}{Geographic Information System}(GIS)
* \href{https://github.com/mitzimorris/ljubljiana_lecture/blob/main/data_prep_spatial_maps.ipynb}{Map-making with Plotnine}

* Course notes: *Software for MCMC* from Odd Kolbjørnsen, Spring 2023, Oslo Uni\
\fontsize{9pt}{9.4}\selectfont
www.uio.no/studier/emner/matnat/math/STK4051/v23/timeplan/lecture_12_softwareformcmc.pdf
\normalsize
