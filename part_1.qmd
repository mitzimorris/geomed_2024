---
title: Spatial Modeling in Stan
author: Mitzi Morris
institute: Stan Development Team
date: Sept 9, 2024
format:
  beamer:
    syntax-definitions:
      - "theming/stan.xml"
    highlight-style: tango
    aspectratio: 169
    pdf-engine: pdflatex
    theme: metropolis
    include-in-header: preamble.tex
    navigation: horizontal
    dev: png 
---

# Session 1 Overview

* About Stan

* GLMs in Stan

* ICAR Model for Spatial Smoothing



# What is Stan?

\tightlist
* A Probabilistic Programming Language
  + A Stan program defines a probability model

\vspace*{4pt}
* A Collection of Inference Algorithms
  + Exact Bayesian inference using MCMC (NUTS-HMC)
  + Aproximate Bayesian inference using ADVI, Pathfinder
  + Point estimates using optimization, Laplace approximation

\vspace*{4pt}
* Interfaces and Analysis Tools
  + R: [CmdStanR](https://mc-stan.org/cmdstanr/), [Posterior](https://mc-stan.org/posterior/), [Bayesplot](https://mc-stan.org/bayesplot/), [LOO](https://mc-stan.org/loo/) (Also:  RStan, RStanARM, BRMS)
  + Python: [CmdStanPy](https://mc-stan.org/cmdstanpy/), [ArviZ](https://python.arviz.org/en/stable/)
  + Julia: [Stan.jl](https://stanjulia.github.io/Stan.jl/v10.8/), [ArviZ.jl](https://julia.arviz.org/ArviZ/stable/)
  + Command shell: [CmdStan](https://mc-stan.org/docs/cmdstan-guide/)


# Why Stan?

\tightlist

* **Goal**: Develop multi-level models for real-world applications

\vspace*{8pt}
* *Problem*:  Need descriptive power, clarity of BUGS
* *Solution*: Compile a domain-specific language

 . . .

\vspace*{8pt}
* *Problem*:  Pure directed graphical language inflexible
* *Solution*: Imperative probabilistic programming language

 . . .

\vspace*{8pt}
* *Problem*:  Heterogeneous user base
* *Solution*: Many interfaces (R, Python, Julia, Mathematica, MATLAB), domain-specific examples, case studies, and field guides

 . . .

\vspace*{8pt}
* *Problem*:  Restrictive licensing limits use
* *Solution*: Code and doc open source (BSD, CC-BY)

# Why Stan?

\tightlist
* **Goal**: Robust, fully Bayesian inference.

\vspace*{8pt}
* *Problem*: Gibbs and Metropolis too slow (diffusive)
* *Solution*: Hamiltonian Monte Carlo (flow of Hamiltonian dynamics)

 . . .

\vspace*{8pt}
* *Problem*:  Need to tune parameters for HMC
* *Solution*: Tune step size and estimate mass matrix during warmup;\
determine number of steps on-the-fly (NUTS)

 . . .

\vspace*{8pt}
* *Problem*:  Need gradients of log posterior for HMC
* *Solution*: Reverse-mode algorithmic differentiation

 . . .

\vspace*{8pt}
* *Problem*:  Need unconstrained parameters for HMC
* *Solution*: Variable transforms w. Jacobian determinants

# NUTS-HMC vs.\ Gibbs and Metropolis

\includegraphics[width=0.9\textwidth]{img/nuts-vs.pdf}

* Plot shows 2 dimensions of highly correlated 250-dim normal
* **1,000,000 draws** from Metropolis and Gibbs (thin to 1000)
* **1000 draws** from NUTS (no thinning); 1000 independent draws
\fontsize{9pt}{9.4}\selectfont
* [*The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo*](http://jmlr.org/papers/v15/hoffman14a.html), fig. 7
\normalsize

# MCMC Sampling Efficiency
\tightlist
* MCMC samples have autocorrelation

* $N_{\mbox{\footnotesize eff}}$ is the number of independent samples with the same estimation power as the $N$ autocorrelated samples.

* We care about **$N_{\mbox{\footnotesize eff}}$ per second**
  + Effective samples per iteration; iterations per second; 

\vspace{0.05in}
* Gibbs and Metropolis have
  + High iterations per second but low effective samples per iteration
  + Both are weak when there is high correlation among the parameters in the posterior

\vspace{0.05in}
* Hamiltonian Monte Carlo \& NUTS
  + Fewer iterations per second than Gibbs or Metropolis
  + But *much* higher $N_{\mbox{\footnotesize eff}}$ per second
  + More robust to highly correlated or differently scaled parameters.

# Other Supported Inference Algorithms

Faster, more scalable methods
\vspace{0.1in}

\tightlist
* Variational Inference\
Generate samples from a variational approximation to the posterior distribution
   + [ADVI](https://www.jmlr.org/papers/volume18/16-107/16-107.pdf) - use stochastic gradient ascent
   + Pathfinder - follow quasi-Newton optimization path


\vspace{0.05in}
* Optimization: find posterior mode
   + MLE - maximum likelihood estimate (of the data given the parameters)
   + MAP - maximum a posteriori estimate (of the value of the posterior density\
on the unconstrained scale)
   + Laplace approximation - obtain samples from posterior mode


# Stan Toolset

* Programming language interfaces:  CmdStanR, CmdStanPy, Stan.jl, (MatLabStan)
  + Core methods for model compilation, doing inference, accessing results

\vspace{0.05in}
* Tools for visualization and validation:  Bayesplot, LOO, ArviZ, Arviz.jl
  + Evaluate the goodness of fit; make plots to communicate findings
  
\vspace{0.05in}
* Higher Level Interface for R: BRMS - Bayesian Regression Models in Stan
  + Model specification via extended R formula, data supplied as R dataframe
  + BRMS translates formula to Stan, creates list of inputs from dataframe,\
runs NUTS-HMC sampler, checks inferences.


\vspace{0.05in}
* BridgeStan - algorithm development and exploration
  + Evaluate the log posterior density at a point
  + Constrain/unconstrain model parameters


# The Stan Language

\tightlist
* A Stan program
  + Declares data and (constrained) parameter variables
  + Defines log posterior (or penalized likelihood)
  + Computes quantities of interest

* Syntax
  + Influenced by BUGS (plus Java/C++ punctuation)
  + Explicit variable types (like Java/C++, not like Python, R)
  + Named program blocks - distinguish between data and parameters (not like BUGS)
  + Control flow:  `if` statements - dynamic branch points (more powerful than BUGS)

* Mathematical operations
  + Stan language includes a very large set of probability distributions\
and mathematical functions from Stan's math library
  + Efficient, vectorized (almost always)


# The Stan Language

A Stan file consists of one or more named program blocks, strictly ordered

\fontsize{9pt}{9.4}\selectfont
```stan
functions {
  // declare, define functions
} data {
  // declare input data
} transformed data {
   // data variable transforms
} parameters {
   // declare (continuous) parameters
} transformed parameters {
   // parameter variable transforms
} model {
   // compute the log joint distribution
} generated quantities {
   // declare, compute quantities of interest
}
```
\normalsize


# The Stan Language

\tightlist
* Variables have strong, static types
  + Strong:  only values of that type will be assignable to the variable,\
(type promotion allowed, e.g., `int` to `real`, `complex`).
  + Static: variable type is constant throughout program
  + Rich set of [vector and matrix types](https://mc-stan.org/docs/reference-manual/types.html#vector-and-matrix-data-types)
  + Variable constraints include bounds, affine transforms of scalars 
  
* Motivation
  + Static types make programs easier to comprehend, debug, and maintain
  + Programming errors can be detected at compile-time
  + Constrained types catch runtime errors

\vspace*{4pt}
\fontsize{9pt}{9.4}\selectfont
```stan
  int<lower=0> N, n_grade;  // constraint applies to both N, n_grade
  array[N] int<lower=0, upper=n_grade> grade;
  vector<lower=-1, upper=1>[3] rho;
  matrix[M, N] B;
```




# Stan Example: Laplace's Model of Birth Rate by Sex

\vspace{-0.1in}
Laplace's data on live births in Paris from 1745--1770:

\begin{center}\small
\begin{tabular}{c|c}
{\slshape sex} & {\slshape live births}
\\ \hline
female & 241\,945
\\
male & 251\,527
\end{tabular}
\end{center}

\vspace*{0.1in}

* *Question 1* (Estimation): What is the birth rate of boys vs. girls?

* *Question 2* (Event Probability): Is a boy more likely to be born than a girl?


\vspace*{0.15in}
Laplace computed this analytically.  Let's use Stan's NUTS-HMC sampler instead.


# Laplace's Model in Stan

\fontsize{9pt}{9.4}\selectfont
```stan
transformed data {
  int male = 251527;
  int female = 241945;
}
parameters {
  real<lower=0, upper=1> theta;
}
model {
  male ~ binomial(male + female, theta);
}
generated quantities {
  int<lower=0, upper=1> theta_gt_half = (theta > 0.5);
}
```
\normalsize


# Laplace's Answer
\vspace{-0.1in}

\fontsize{9pt}{9.4}\selectfont
```
births_model = cmdstan_model("laplace.stan")   # compile model
births_fit = births_model$sample()             # run inference algorithm
as.data.frame(births_fit$summary())            # manage results

      variable       mean     median       sd         q5         q95

         theta       0.51       0.51 0.000725      0.509       0.511
 theta_gt_half       1.00       1.00 0.000000      1.000       1.000
```
\normalsize

\vspace{0.1in}
* *Question 1* (Estimation): What is the birth rate of boys vs. girls?\
$\theta$ is 90\% certain to lie in $(0.509, 0.511)$

* *Question 2* (Event Probability): Is a boy more likely to be born than a girl?\
Laplace "morally certain" boys more prevalent

# Processing Steps

* Compile model
  + Stan compiler translates Stan file to C++ file
  + C++ file is compiled to executable program, via GNU Make
  + *prerequisites: a C++17 compiler, GNU-Make*\
*both CmdStanPy and CmdStanR have utilities to install these*

* Run inference algorithm
  + Interfaces run compiled executable program (as subprocess)
  + Compiled executable generates per-chain output files (modified CSV format)

* Get results via interface methods
  + Parse CSV outputs into in-memory object
  + Access individual parameters and quantities of interest
  + Run summary and diagnostic reports


# Install Stan

\tightlist
*  If you don't already have Stan running on your machine, 10 minutes to get it working now.
   + *If you already have Stan running on your machine, please help your neighbor.*

\vspace*{8pt}
* See notebook:  ....


\vspace*{8pt}
* Install package, build CmdStan (as needed)

\vspace*{8pt}
* Compile, run Laplace Stan

\vspace*{8pt}
* Bonus activity: Modify Laplace Stan
  + Change `transformed data` block to `data block`
  + Run with list of inputs: {"male",  "female"}


# Notebook One:  Multi-level Regression Models in Stan

Poisson regression:  disease rate per area, complete data:  all events recorded, population known

# Programming Pitfalls

* Pitfall: too many ways to go wrong.
* Defense: start with too simple model, build up a model piecewise

* Pitfall: the call of complexity
* Defense: compare to simpler version

* Pitfall: failure to generalize
* Defense: prior predictive tests, posterior predictive tests

# Notebook Two: ICAR model



# References


* \href{https://mc-stan.org/docs/stan-users-guide/index.html}{Stan User's Guide}
* \href{https://bob-carpenter.github.io/stan-getting-started/stan-getting-started.html}{Getting Started with Bayesian Statistics}
* \href {https://www.usgs.gov/faqs/what-geographic-information-system-gis}{Geographic Information System}(GIS)
* \href{https://github.com/mitzimorris/ljubljiana_lecture/blob/main/data_prep_spatial_maps.ipynb}{Map-making with Plotnine}

* \{https://www.uio.no/studier/emner/matnat/math/STK4051/v23/timeplan/lecture_12_softwareformcmc.pdf}{Software for MCMC}, a very nice set of course notes from Odd Kolbjørnsen, Spring 2023, Oslo Uni.

\textit{Questions?}
